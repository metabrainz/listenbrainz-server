version: "3.4"

# IMPORTANT NOTE: Volume paths mounted on containers are relative to the
# directory that this file is in (`docker/`) and so probably need to start with
# `../` to refer to a directory in the main code checkout

volumes:
  namenode:
  datanode:

services:
  hadoop-master:
    image: metabrainz/hadoop-yarn:beta
    command: bash -c "rm -f /tmp/hadoop-root-namenode.pid && hdfs namenode"
    volumes:
      - namenode:/home/hadoop/hdfs:z

  datanode:
    image: metabrainz/hadoop-yarn:beta
    command: bash -c "rm -f /tmp/hadoop-root-datanode.pid && hdfs datanode"
    volumes:
      - datanode:/home/hadoop/hdfs:z
    depends_on:
      - hadoop-master

  request_consumer:
    build:
      context: ..
      dockerfile: Dockerfile.spark
      target: metabrainz-spark-dev
    command: bash -c "zip -r /rec/listenbrainz_spark.zip listenbrainz_spark/ ; python spark_manage.py request_consumer"
    volumes:
      - ..:/rec:z

networks:
  default:
    external:
      name: listenbrainz_default
