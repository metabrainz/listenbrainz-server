HDFS_HTTP_URI = 'http://hadoop-master:9870' # the URI of the http webclient for HDFS

HDFS_CLUSTER_URI = 'hdfs://hadoop-master:9000' # the URI to be used with Spark

#rabbitmq
RABBITMQ_HOST = "rabbitmq"
RABBITMQ_PORT = 5672
RABBITMQ_USERNAME = "guest"
RABBITMQ_PASSWORD = "guest"
RABBITMQ_VHOST = "/"
MAXIMUM_RABBITMQ_CONNECTIONS = 100
SPARK_EXCHANGE = "spark"
SPARK_QUEUE = "spark"

# train model
RANKS = [8, 12]
LAMBDAS = [0.1, 10.0]
ITERATIONS = [10, 20]

# create dataframes
STARTING_MONTH = 1
ENDING_MONTH = 12
STARTING_YEAR = 2017
ENDING_YEAR = 2019

# number of recommendations to generate
RECOMMENDATION_TOP_ARTIST_LIMIT = 30
RECOMMENDATION_SIMILAR_ARTIST_LIMIT = 30

# candidate sets
TOP_ARTISTS_LIMIT = 20
SIMILAR_ARTISTS_LIMIT = 10
