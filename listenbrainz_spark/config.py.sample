HDFS_HTTP_URI = 'http://hadoop-master:9870' # the URI of the http webclient for HDFS

HDFS_CLUSTER_URI = 'hdfs://hadoop-master:9000' # the URI to be used with Spark

# rabbitmq
RABBITMQ_HOST = "rabbitmq"
RABBITMQ_PORT = 5672
RABBITMQ_USERNAME = "guest"
RABBITMQ_PASSWORD = "guest"
RABBITMQ_VHOST = "/"
MAXIMUM_RABBITMQ_CONNECTIONS = 100

# rabbitmq exchange and queue for stats
SPARK_EXCHANGE = "spark"
SPARK_QUEUE = "spark"

# train model
RANKS = [8, 12]
LAMBDAS = [0.1, 10.0]
ITERATIONS = [10, 20]

# train model on X months data
TRAIN_MODEL_WINDOW = 6

# calculate stats on X months data
STATS_CALCULATION_WINDOW = 1

# generate recommendations after every X days
RECOMMENDATION_GENERATION_WINDOW = 28

# number of recommendations to generate
RECOMMENDATION_TOP_ARTIST_LIMIT = 30
RECOMMENDATION_SIMILAR_ARTIST_LIMIT = 30

# candidate sets
TOP_ARTISTS_LIMIT = 20
SIMILAR_ARTISTS_LIMIT = 10
