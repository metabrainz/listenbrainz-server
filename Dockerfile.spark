FROM metabrainz/listenbrainz-spark-base:latest

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
                       zstd \
    && rm -rf /var/lib/apt/lists/*

COPY docker/spark-cluster-config/test/core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml
COPY docker/spark-cluster-config/test/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml
COPY docker/spark-cluster-config/test/spark-env.sh $SPARK_HOME/conf/spark-env.sh

RUN pip3 install pip==25.0.1 setuptools wheel

WORKDIR /rec

COPY requirements_spark.txt /rec/requirements_spark.txt
RUN pip3 install -r requirements_spark.txt

COPY requirements_development.txt /rec/requirements_development.txt
RUN pip3 install -r requirements_development.txt
